{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,  51., 159., 253., 159.,  50.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        48., 238., 252., 252., 252., 237.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  54., 227., 253., 252., 239., 233.,\n",
       "       252.,  57.,   6.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  10.,  60.,\n",
       "       224., 252., 253., 252., 202.,  84., 252., 253., 122.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0., 163., 252., 252., 252., 253., 252., 252.,\n",
       "        96., 189., 253., 167.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  51., 238.,\n",
       "       253., 253., 190., 114., 253., 228.,  47.,  79., 255., 168.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,  48., 238., 252., 252., 179.,  12.,  75., 121.,\n",
       "        21.,   0.,   0., 253., 243.,  50.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  38., 165., 253.,\n",
       "       233., 208.,  84.,   0.,   0.,   0.,   0.,   0.,   0., 253., 252.,\n",
       "       165.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   7., 178., 252., 240.,  71.,  19.,  28.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0., 253., 252., 195.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  57., 252., 252.,\n",
       "        63.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 253.,\n",
       "       252., 195.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0., 198., 253., 190.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0., 255., 253., 196.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  76., 246., 252.,\n",
       "       112.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       253., 252., 148.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,  85., 252., 230.,  25.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   7., 135., 253., 186.,  12.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  85., 252.,\n",
       "       223.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   7., 131.,\n",
       "       252., 225.,  71.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,  85., 252., 145.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,  48., 165., 252., 173.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  86.,\n",
       "       253., 225.,   0.,   0.,   0.,   0.,   0.,   0., 114., 238., 253.,\n",
       "       162.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  85., 252., 249., 146.,  48.,  29.,\n",
       "        85., 178., 225., 253., 223., 167.,  56.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        85., 252., 252., 252., 229., 215., 252., 252., 252., 196., 130.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,  28., 199., 252., 252., 253.,\n",
       "       252., 252., 233., 145.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  25., 128., 252., 253., 252., 141.,  37.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[1].reshape((28,28)),cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(x)\n",
    "df.insert(784, \"Label\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3    4    5    6    7    8    9  ...  775  776  777  \\\n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "69995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "69996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "69997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "69998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "69999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "       778  779  780  781  782  783  Label  \n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0      5  \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0      0  \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0      4  \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0      1  \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0      9  \n",
       "...    ...  ...  ...  ...  ...  ...    ...  \n",
       "69995  0.0  0.0  0.0  0.0  0.0  0.0      2  \n",
       "69996  0.0  0.0  0.0  0.0  0.0  0.0      3  \n",
       "69997  0.0  0.0  0.0  0.0  0.0  0.0      4  \n",
       "69998  0.0  0.0  0.0  0.0  0.0  0.0      5  \n",
       "69999  0.0  0.0  0.0  0.0  0.0  0.0      6  \n",
       "\n",
       "[70000 rows x 785 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y, random_state=0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['4', '9', '6', ..., '7', '1', '1'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '4', '1', ..., '7', '4', '6'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp1 = MLPClassifier(hidden_layer_sizes=1, activation=\"logistic\")\n",
    "mlp2 = MLPClassifier(hidden_layer_sizes=10, activation=\"logistic\")\n",
    "mlp3 = MLPClassifier(hidden_layer_sizes=100, activation=\"logistic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp1.fit(x_train,y_train)\n",
    "mlp2.fit(x_train,y_train)\n",
    "mlp3.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts1 = mlp1.predict(x_test)\n",
    "predicts2 = mlp2.predict(x_test)\n",
    "predicts3 = mlp3.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Value:4\n",
      "Predicted Value For 1 Hidden Layer:6\n",
      "Predicted Value For 100 Hidden Layer:4\n",
      "Predicted Value For 1000 Hidden Layer:4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Actual Value:{y_test[1]}\")\n",
    "print(f\"Predicted Value For 1 Hidden Layer:{predicts1[1]}\")\n",
    "print(f\"Predicted Value For 100 Hidden Layer:{predicts2[1]}\")\n",
    "print(f\"Predicted Value For 1000 Hidden Layer:{predicts3[1]}\")\n",
    "\n",
    "plt.imshow(x_test[1].reshape(28,28),cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    6,    1,    1,    0,    0, 1379,    0,    0,    0],\n",
       "       [   0, 1545,    0,    1,    2,    0,   32,    0,    0,    0],\n",
       "       [   0,  128,    1,    1,    3,    0, 1310,    0,    0,    0],\n",
       "       [   0, 1204,    1,    1,    2,    0,  227,    0,    0,    0],\n",
       "       [   0,  226,    2,    0,    3,    0, 1119,    0,    0,    0],\n",
       "       [   0,  119,    0,    1,    1,    0, 1110,    0,    0,    0],\n",
       "       [   0,    5,    0,    0,    0,    0, 1382,    0,    0,    0],\n",
       "       [   0, 1416,    1,    0,    1,    0,   40,    0,    0,    0],\n",
       "       [   0,  247,    1,    3,    3,    0, 1114,    0,    0,    0],\n",
       "       [   0, 1200,    0,    0,    2,    0,  159,    0,    0,    0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,predicts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1387\n",
      "           1       0.25      0.98      0.40      1580\n",
      "           2       0.14      0.00      0.00      1443\n",
      "           3       0.12      0.00      0.00      1435\n",
      "           4       0.18      0.00      0.00      1350\n",
      "           5       0.00      0.00      0.00      1231\n",
      "           6       0.18      1.00      0.30      1387\n",
      "           7       0.00      0.00      0.00      1458\n",
      "           8       0.00      0.00      0.00      1368\n",
      "           9       0.00      0.00      0.00      1361\n",
      "\n",
      "    accuracy                           0.21     14000\n",
      "   macro avg       0.09      0.20      0.07     14000\n",
      "weighted avg       0.09      0.21      0.08     14000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Orhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Orhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Orhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predicts1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1326,    1,    7,    3,    7,   14,   19,    4,    4,    2],\n",
       "       [   0, 1503,   38,    6,    3,    3,    1,    6,   12,    8],\n",
       "       [  31,    3, 1218,   33,   37,    6,   59,   17,   31,    8],\n",
       "       [  16,    7,   58, 1174,    3,   89,    8,   19,   43,   18],\n",
       "       [   4,    1,    6,    1, 1269,    2,   16,    8,    2,   41],\n",
       "       [  21,    7,    8,   40,   13, 1062,   39,    6,   16,   19],\n",
       "       [  16,    5,    8,    0,   13,   25, 1311,    4,    5,    0],\n",
       "       [  10,   17,   15,   12,   36,    6,    4, 1310,   12,   36],\n",
       "       [  43,   27,   16,   28,   13,   60,   22,    7, 1107,   45],\n",
       "       [   8,    3,    4,    8,   71,   20,    6,   59,   12, 1170]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,predicts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93      1387\n",
      "           1       0.95      0.95      0.95      1580\n",
      "           2       0.88      0.84      0.86      1443\n",
      "           3       0.90      0.82      0.86      1435\n",
      "           4       0.87      0.94      0.90      1350\n",
      "           5       0.83      0.86      0.84      1231\n",
      "           6       0.88      0.95      0.91      1387\n",
      "           7       0.91      0.90      0.90      1458\n",
      "           8       0.89      0.81      0.85      1368\n",
      "           9       0.87      0.86      0.86      1361\n",
      "\n",
      "    accuracy                           0.89     14000\n",
      "   macro avg       0.89      0.89      0.89     14000\n",
      "weighted avg       0.89      0.89      0.89     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predicts2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1371,    0,    1,    0,    1,    3,    4,    1,    4,    2],\n",
       "       [   0, 1552,    6,    2,    3,    2,    2,    3,    8,    2],\n",
       "       [   6,    5, 1371,   16,    7,    3,    7,    8,   16,    4],\n",
       "       [   6,    5,   29, 1336,    2,   22,    0,   10,   18,    7],\n",
       "       [   2,    1,    5,    1, 1282,    0,   10,   10,    3,   36],\n",
       "       [   5,    5,    3,   15,    3, 1165,   15,    1,   10,    9],\n",
       "       [  16,    3,    4,    0,    5,    9, 1339,    4,    7,    0],\n",
       "       [   2,    9,   16,   14,    8,    1,    2, 1385,    4,   17],\n",
       "       [  11,   11,   10,   10,    3,   17,    8,    7, 1273,   18],\n",
       "       [   5,    3,    2,    9,   32,    8,    0,   29,   13, 1260]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,predicts3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      1387\n",
      "           1       0.97      0.98      0.98      1580\n",
      "           2       0.95      0.95      0.95      1443\n",
      "           3       0.95      0.93      0.94      1435\n",
      "           4       0.95      0.95      0.95      1350\n",
      "           5       0.95      0.95      0.95      1231\n",
      "           6       0.97      0.97      0.97      1387\n",
      "           7       0.95      0.95      0.95      1458\n",
      "           8       0.94      0.93      0.93      1368\n",
      "           9       0.93      0.93      0.93      1361\n",
      "\n",
      "    accuracy                           0.95     14000\n",
      "   macro avg       0.95      0.95      0.95     14000\n",
      "weighted avg       0.95      0.95      0.95     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predicts3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8156a36ef2b5e5cc1ebda271ff76bc51e3d60fa787ad119300a3a2fb77f01d4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
