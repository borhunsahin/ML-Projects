{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder,minmax_scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"date_fruit.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AREA</th>\n",
       "      <th>PERIMETER</th>\n",
       "      <th>MAJOR_AXIS</th>\n",
       "      <th>MINOR_AXIS</th>\n",
       "      <th>ECCENTRICITY</th>\n",
       "      <th>EQDIASQ</th>\n",
       "      <th>SOLIDITY</th>\n",
       "      <th>CONVEX_AREA</th>\n",
       "      <th>EXTENT</th>\n",
       "      <th>ASPECT_RATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>KurtosisRR</th>\n",
       "      <th>KurtosisRG</th>\n",
       "      <th>KurtosisRB</th>\n",
       "      <th>EntropyRR</th>\n",
       "      <th>EntropyRG</th>\n",
       "      <th>EntropyRB</th>\n",
       "      <th>ALLdaub4RR</th>\n",
       "      <th>ALLdaub4RG</th>\n",
       "      <th>ALLdaub4RB</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>422163</td>\n",
       "      <td>2378.9080</td>\n",
       "      <td>837.8484</td>\n",
       "      <td>645.6693</td>\n",
       "      <td>0.6373</td>\n",
       "      <td>733.1539</td>\n",
       "      <td>0.9947</td>\n",
       "      <td>424428</td>\n",
       "      <td>0.7831</td>\n",
       "      <td>1.2976</td>\n",
       "      <td>...</td>\n",
       "      <td>3.2370</td>\n",
       "      <td>2.9574</td>\n",
       "      <td>4.2287</td>\n",
       "      <td>-59191263232</td>\n",
       "      <td>-50714214400</td>\n",
       "      <td>-39922372608</td>\n",
       "      <td>58.7255</td>\n",
       "      <td>54.9554</td>\n",
       "      <td>47.8400</td>\n",
       "      <td>BERHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>338136</td>\n",
       "      <td>2085.1440</td>\n",
       "      <td>723.8198</td>\n",
       "      <td>595.2073</td>\n",
       "      <td>0.5690</td>\n",
       "      <td>656.1464</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>339014</td>\n",
       "      <td>0.7795</td>\n",
       "      <td>1.2161</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6228</td>\n",
       "      <td>2.6350</td>\n",
       "      <td>3.1704</td>\n",
       "      <td>-34233065472</td>\n",
       "      <td>-37462601728</td>\n",
       "      <td>-31477794816</td>\n",
       "      <td>50.0259</td>\n",
       "      <td>52.8168</td>\n",
       "      <td>47.8315</td>\n",
       "      <td>BERHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>526843</td>\n",
       "      <td>2647.3940</td>\n",
       "      <td>940.7379</td>\n",
       "      <td>715.3638</td>\n",
       "      <td>0.6494</td>\n",
       "      <td>819.0222</td>\n",
       "      <td>0.9962</td>\n",
       "      <td>528876</td>\n",
       "      <td>0.7657</td>\n",
       "      <td>1.3150</td>\n",
       "      <td>...</td>\n",
       "      <td>3.7516</td>\n",
       "      <td>3.8611</td>\n",
       "      <td>4.7192</td>\n",
       "      <td>-93948354560</td>\n",
       "      <td>-74738221056</td>\n",
       "      <td>-60311207936</td>\n",
       "      <td>65.4772</td>\n",
       "      <td>59.2860</td>\n",
       "      <td>51.9378</td>\n",
       "      <td>BERHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>416063</td>\n",
       "      <td>2351.2100</td>\n",
       "      <td>827.9804</td>\n",
       "      <td>645.2988</td>\n",
       "      <td>0.6266</td>\n",
       "      <td>727.8378</td>\n",
       "      <td>0.9948</td>\n",
       "      <td>418255</td>\n",
       "      <td>0.7759</td>\n",
       "      <td>1.2831</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0401</td>\n",
       "      <td>8.6136</td>\n",
       "      <td>8.2618</td>\n",
       "      <td>-32074307584</td>\n",
       "      <td>-32060925952</td>\n",
       "      <td>-29575010304</td>\n",
       "      <td>43.3900</td>\n",
       "      <td>44.1259</td>\n",
       "      <td>41.1882</td>\n",
       "      <td>BERHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>347562</td>\n",
       "      <td>2160.3540</td>\n",
       "      <td>763.9877</td>\n",
       "      <td>582.8359</td>\n",
       "      <td>0.6465</td>\n",
       "      <td>665.2291</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>350797</td>\n",
       "      <td>0.7569</td>\n",
       "      <td>1.3108</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7016</td>\n",
       "      <td>2.9761</td>\n",
       "      <td>4.4146</td>\n",
       "      <td>-39980974080</td>\n",
       "      <td>-35980042240</td>\n",
       "      <td>-25593278464</td>\n",
       "      <td>52.7743</td>\n",
       "      <td>50.9080</td>\n",
       "      <td>42.6666</td>\n",
       "      <td>BERHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>255403</td>\n",
       "      <td>1925.3650</td>\n",
       "      <td>691.8453</td>\n",
       "      <td>477.1796</td>\n",
       "      <td>0.7241</td>\n",
       "      <td>570.2536</td>\n",
       "      <td>0.9785</td>\n",
       "      <td>261028</td>\n",
       "      <td>0.7269</td>\n",
       "      <td>1.4499</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2423</td>\n",
       "      <td>2.3704</td>\n",
       "      <td>2.7202</td>\n",
       "      <td>-25296416768</td>\n",
       "      <td>-19168882688</td>\n",
       "      <td>-18473392128</td>\n",
       "      <td>49.0869</td>\n",
       "      <td>43.0422</td>\n",
       "      <td>42.4153</td>\n",
       "      <td>SOGAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>365924</td>\n",
       "      <td>2664.8230</td>\n",
       "      <td>855.4633</td>\n",
       "      <td>551.5447</td>\n",
       "      <td>0.7644</td>\n",
       "      <td>682.5752</td>\n",
       "      <td>0.9466</td>\n",
       "      <td>386566</td>\n",
       "      <td>0.6695</td>\n",
       "      <td>1.5510</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4109</td>\n",
       "      <td>3.5805</td>\n",
       "      <td>3.9910</td>\n",
       "      <td>-31605219328</td>\n",
       "      <td>-21945366528</td>\n",
       "      <td>-19277905920</td>\n",
       "      <td>46.8086</td>\n",
       "      <td>39.1046</td>\n",
       "      <td>36.5502</td>\n",
       "      <td>SOGAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>254330</td>\n",
       "      <td>1926.7360</td>\n",
       "      <td>747.4943</td>\n",
       "      <td>435.6219</td>\n",
       "      <td>0.8126</td>\n",
       "      <td>569.0545</td>\n",
       "      <td>0.9925</td>\n",
       "      <td>256255</td>\n",
       "      <td>0.7240</td>\n",
       "      <td>1.7159</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2759</td>\n",
       "      <td>2.5090</td>\n",
       "      <td>2.6951</td>\n",
       "      <td>-22242772992</td>\n",
       "      <td>-19594921984</td>\n",
       "      <td>-17592152064</td>\n",
       "      <td>44.1325</td>\n",
       "      <td>40.7986</td>\n",
       "      <td>40.9769</td>\n",
       "      <td>SOGAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>238955</td>\n",
       "      <td>1906.2679</td>\n",
       "      <td>716.6485</td>\n",
       "      <td>441.8297</td>\n",
       "      <td>0.7873</td>\n",
       "      <td>551.5859</td>\n",
       "      <td>0.9604</td>\n",
       "      <td>248795</td>\n",
       "      <td>0.6954</td>\n",
       "      <td>1.6220</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6769</td>\n",
       "      <td>2.6874</td>\n",
       "      <td>2.7991</td>\n",
       "      <td>-26048595968</td>\n",
       "      <td>-21299822592</td>\n",
       "      <td>-19809978368</td>\n",
       "      <td>51.2267</td>\n",
       "      <td>45.7162</td>\n",
       "      <td>45.6260</td>\n",
       "      <td>SOGAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>343792</td>\n",
       "      <td>2289.2720</td>\n",
       "      <td>823.8438</td>\n",
       "      <td>534.7757</td>\n",
       "      <td>0.7607</td>\n",
       "      <td>661.6113</td>\n",
       "      <td>0.9781</td>\n",
       "      <td>351472</td>\n",
       "      <td>0.6941</td>\n",
       "      <td>1.5405</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5138</td>\n",
       "      <td>3.0369</td>\n",
       "      <td>3.0865</td>\n",
       "      <td>-31983476736</td>\n",
       "      <td>-20482514944</td>\n",
       "      <td>-21219354624</td>\n",
       "      <td>47.3454</td>\n",
       "      <td>38.6966</td>\n",
       "      <td>39.6738</td>\n",
       "      <td>SOGAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>898 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AREA  PERIMETER  MAJOR_AXIS  MINOR_AXIS  ECCENTRICITY   EQDIASQ  \\\n",
       "0    422163  2378.9080    837.8484    645.6693        0.6373  733.1539   \n",
       "1    338136  2085.1440    723.8198    595.2073        0.5690  656.1464   \n",
       "2    526843  2647.3940    940.7379    715.3638        0.6494  819.0222   \n",
       "3    416063  2351.2100    827.9804    645.2988        0.6266  727.8378   \n",
       "4    347562  2160.3540    763.9877    582.8359        0.6465  665.2291   \n",
       "..      ...        ...         ...         ...           ...       ...   \n",
       "893  255403  1925.3650    691.8453    477.1796        0.7241  570.2536   \n",
       "894  365924  2664.8230    855.4633    551.5447        0.7644  682.5752   \n",
       "895  254330  1926.7360    747.4943    435.6219        0.8126  569.0545   \n",
       "896  238955  1906.2679    716.6485    441.8297        0.7873  551.5859   \n",
       "897  343792  2289.2720    823.8438    534.7757        0.7607  661.6113   \n",
       "\n",
       "     SOLIDITY  CONVEX_AREA  EXTENT  ASPECT_RATIO  ...  KurtosisRR  KurtosisRG  \\\n",
       "0      0.9947       424428  0.7831        1.2976  ...      3.2370      2.9574   \n",
       "1      0.9974       339014  0.7795        1.2161  ...      2.6228      2.6350   \n",
       "2      0.9962       528876  0.7657        1.3150  ...      3.7516      3.8611   \n",
       "3      0.9948       418255  0.7759        1.2831  ...      5.0401      8.6136   \n",
       "4      0.9908       350797  0.7569        1.3108  ...      2.7016      2.9761   \n",
       "..        ...          ...     ...           ...  ...         ...         ...   \n",
       "893    0.9785       261028  0.7269        1.4499  ...      2.2423      2.3704   \n",
       "894    0.9466       386566  0.6695        1.5510  ...      3.4109      3.5805   \n",
       "895    0.9925       256255  0.7240        1.7159  ...      2.2759      2.5090   \n",
       "896    0.9604       248795  0.6954        1.6220  ...      2.6769      2.6874   \n",
       "897    0.9781       351472  0.6941        1.5405  ...      2.5138      3.0369   \n",
       "\n",
       "     KurtosisRB    EntropyRR    EntropyRG    EntropyRB  ALLdaub4RR  \\\n",
       "0        4.2287 -59191263232 -50714214400 -39922372608     58.7255   \n",
       "1        3.1704 -34233065472 -37462601728 -31477794816     50.0259   \n",
       "2        4.7192 -93948354560 -74738221056 -60311207936     65.4772   \n",
       "3        8.2618 -32074307584 -32060925952 -29575010304     43.3900   \n",
       "4        4.4146 -39980974080 -35980042240 -25593278464     52.7743   \n",
       "..          ...          ...          ...          ...         ...   \n",
       "893      2.7202 -25296416768 -19168882688 -18473392128     49.0869   \n",
       "894      3.9910 -31605219328 -21945366528 -19277905920     46.8086   \n",
       "895      2.6951 -22242772992 -19594921984 -17592152064     44.1325   \n",
       "896      2.7991 -26048595968 -21299822592 -19809978368     51.2267   \n",
       "897      3.0865 -31983476736 -20482514944 -21219354624     47.3454   \n",
       "\n",
       "     ALLdaub4RG  ALLdaub4RB  Class  \n",
       "0       54.9554     47.8400  BERHI  \n",
       "1       52.8168     47.8315  BERHI  \n",
       "2       59.2860     51.9378  BERHI  \n",
       "3       44.1259     41.1882  BERHI  \n",
       "4       50.9080     42.6666  BERHI  \n",
       "..          ...         ...    ...  \n",
       "893     43.0422     42.4153  SOGAY  \n",
       "894     39.1046     36.5502  SOGAY  \n",
       "895     40.7986     40.9769  SOGAY  \n",
       "896     45.7162     45.6260  SOGAY  \n",
       "897     38.6966     39.6738  SOGAY  \n",
       "\n",
       "[898 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 898 entries, 0 to 897\n",
      "Data columns (total 35 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   AREA           898 non-null    int64  \n",
      " 1   PERIMETER      898 non-null    float64\n",
      " 2   MAJOR_AXIS     898 non-null    float64\n",
      " 3   MINOR_AXIS     898 non-null    float64\n",
      " 4   ECCENTRICITY   898 non-null    float64\n",
      " 5   EQDIASQ        898 non-null    float64\n",
      " 6   SOLIDITY       898 non-null    float64\n",
      " 7   CONVEX_AREA    898 non-null    int64  \n",
      " 8   EXTENT         898 non-null    float64\n",
      " 9   ASPECT_RATIO   898 non-null    float64\n",
      " 10  ROUNDNESS      898 non-null    float64\n",
      " 11  COMPACTNESS    898 non-null    float64\n",
      " 12  SHAPEFACTOR_1  898 non-null    float64\n",
      " 13  SHAPEFACTOR_2  898 non-null    float64\n",
      " 14  SHAPEFACTOR_3  898 non-null    float64\n",
      " 15  SHAPEFACTOR_4  898 non-null    float64\n",
      " 16  MeanRR         898 non-null    float64\n",
      " 17  MeanRG         898 non-null    float64\n",
      " 18  MeanRB         898 non-null    float64\n",
      " 19  StdDevRR       898 non-null    float64\n",
      " 20  StdDevRG       898 non-null    float64\n",
      " 21  StdDevRB       898 non-null    float64\n",
      " 22  SkewRR         898 non-null    float64\n",
      " 23  SkewRG         898 non-null    float64\n",
      " 24  SkewRB         898 non-null    float64\n",
      " 25  KurtosisRR     898 non-null    float64\n",
      " 26  KurtosisRG     898 non-null    float64\n",
      " 27  KurtosisRB     898 non-null    float64\n",
      " 28  EntropyRR      898 non-null    int64  \n",
      " 29  EntropyRG      898 non-null    int64  \n",
      " 30  EntropyRB      898 non-null    int64  \n",
      " 31  ALLdaub4RR     898 non-null    float64\n",
      " 32  ALLdaub4RG     898 non-null    float64\n",
      " 33  ALLdaub4RB     898 non-null    float64\n",
      " 34  Class          898 non-null    object \n",
      "dtypes: float64(29), int64(5), object(1)\n",
      "memory usage: 245.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AREA</th>\n",
       "      <td>898.0</td>\n",
       "      <td>2.982952e+05</td>\n",
       "      <td>1.072452e+05</td>\n",
       "      <td>1.987000e+03</td>\n",
       "      <td>2.069480e+05</td>\n",
       "      <td>3.198330e+05</td>\n",
       "      <td>3.825730e+05</td>\n",
       "      <td>5.460630e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERIMETER</th>\n",
       "      <td>898.0</td>\n",
       "      <td>2.057661e+03</td>\n",
       "      <td>4.100125e+02</td>\n",
       "      <td>9.118280e+02</td>\n",
       "      <td>1.726091e+03</td>\n",
       "      <td>2.196345e+03</td>\n",
       "      <td>2.389717e+03</td>\n",
       "      <td>2.811997e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAJOR_AXIS</th>\n",
       "      <td>898.0</td>\n",
       "      <td>7.508120e+02</td>\n",
       "      <td>1.440593e+02</td>\n",
       "      <td>3.367227e+02</td>\n",
       "      <td>6.410686e+02</td>\n",
       "      <td>7.913634e+02</td>\n",
       "      <td>8.586338e+02</td>\n",
       "      <td>1.222723e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MINOR_AXIS</th>\n",
       "      <td>898.0</td>\n",
       "      <td>4.958728e+02</td>\n",
       "      <td>1.142689e+02</td>\n",
       "      <td>2.283200e+00</td>\n",
       "      <td>4.046844e+02</td>\n",
       "      <td>4.950548e+02</td>\n",
       "      <td>5.890317e+02</td>\n",
       "      <td>7.664536e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECCENTRICITY</th>\n",
       "      <td>898.0</td>\n",
       "      <td>7.374678e-01</td>\n",
       "      <td>8.872739e-02</td>\n",
       "      <td>3.448000e-01</td>\n",
       "      <td>6.856250e-01</td>\n",
       "      <td>7.547000e-01</td>\n",
       "      <td>8.021500e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EQDIASQ</th>\n",
       "      <td>898.0</td>\n",
       "      <td>6.045779e+02</td>\n",
       "      <td>1.195939e+02</td>\n",
       "      <td>5.029840e+01</td>\n",
       "      <td>5.133171e+02</td>\n",
       "      <td>6.381409e+02</td>\n",
       "      <td>6.979305e+02</td>\n",
       "      <td>8.338279e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOLIDITY</th>\n",
       "      <td>898.0</td>\n",
       "      <td>9.818403e-01</td>\n",
       "      <td>1.815742e-02</td>\n",
       "      <td>8.366000e-01</td>\n",
       "      <td>9.788250e-01</td>\n",
       "      <td>9.873000e-01</td>\n",
       "      <td>9.918000e-01</td>\n",
       "      <td>9.974000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONVEX_AREA</th>\n",
       "      <td>898.0</td>\n",
       "      <td>3.038456e+05</td>\n",
       "      <td>1.088157e+05</td>\n",
       "      <td>2.257000e+03</td>\n",
       "      <td>2.100228e+05</td>\n",
       "      <td>3.272070e+05</td>\n",
       "      <td>3.888040e+05</td>\n",
       "      <td>5.525980e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXTENT</th>\n",
       "      <td>898.0</td>\n",
       "      <td>7.362671e-01</td>\n",
       "      <td>5.374518e-02</td>\n",
       "      <td>5.123000e-01</td>\n",
       "      <td>7.058750e-01</td>\n",
       "      <td>7.469500e-01</td>\n",
       "      <td>7.758500e-01</td>\n",
       "      <td>8.562000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASPECT_RATIO</th>\n",
       "      <td>898.0</td>\n",
       "      <td>2.131102e+00</td>\n",
       "      <td>1.782078e+01</td>\n",
       "      <td>1.065300e+00</td>\n",
       "      <td>1.373725e+00</td>\n",
       "      <td>1.524150e+00</td>\n",
       "      <td>1.674750e+00</td>\n",
       "      <td>5.355257e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUNDNESS</th>\n",
       "      <td>898.0</td>\n",
       "      <td>8.577200e-01</td>\n",
       "      <td>7.083882e-02</td>\n",
       "      <td>4.800000e-03</td>\n",
       "      <td>8.277500e-01</td>\n",
       "      <td>8.677500e-01</td>\n",
       "      <td>8.995000e-01</td>\n",
       "      <td>9.773000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COMPACTNESS</th>\n",
       "      <td>898.0</td>\n",
       "      <td>8.071903e-01</td>\n",
       "      <td>6.217535e-02</td>\n",
       "      <td>4.110000e-02</td>\n",
       "      <td>7.680500e-01</td>\n",
       "      <td>8.049500e-01</td>\n",
       "      <td>8.488750e-01</td>\n",
       "      <td>9.681000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAPEFACTOR_1</th>\n",
       "      <td>898.0</td>\n",
       "      <td>3.428396e-03</td>\n",
       "      <td>2.045601e-02</td>\n",
       "      <td>1.700000e-03</td>\n",
       "      <td>2.200000e-03</td>\n",
       "      <td>2.600000e-03</td>\n",
       "      <td>3.200000e-03</td>\n",
       "      <td>6.154000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAPEFACTOR_2</th>\n",
       "      <td>898.0</td>\n",
       "      <td>1.794432e-03</td>\n",
       "      <td>4.279168e-04</td>\n",
       "      <td>1.100000e-03</td>\n",
       "      <td>1.500000e-03</td>\n",
       "      <td>1.600000e-03</td>\n",
       "      <td>2.075000e-03</td>\n",
       "      <td>4.300000e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAPEFACTOR_3</th>\n",
       "      <td>898.0</td>\n",
       "      <td>6.554197e-01</td>\n",
       "      <td>9.431447e-02</td>\n",
       "      <td>1.700000e-03</td>\n",
       "      <td>5.899750e-01</td>\n",
       "      <td>6.479500e-01</td>\n",
       "      <td>7.206250e-01</td>\n",
       "      <td>9.373000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAPEFACTOR_4</th>\n",
       "      <td>898.0</td>\n",
       "      <td>9.886796e-01</td>\n",
       "      <td>2.047314e-02</td>\n",
       "      <td>7.568000e-01</td>\n",
       "      <td>9.893000e-01</td>\n",
       "      <td>9.936000e-01</td>\n",
       "      <td>9.964000e-01</td>\n",
       "      <td>9.995000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MeanRR</th>\n",
       "      <td>898.0</td>\n",
       "      <td>1.001659e+02</td>\n",
       "      <td>3.212655e+01</td>\n",
       "      <td>3.038260e+01</td>\n",
       "      <td>7.644800e+01</td>\n",
       "      <td>1.076825e+02</td>\n",
       "      <td>1.261275e+02</td>\n",
       "      <td>1.596494e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MeanRG</th>\n",
       "      <td>898.0</td>\n",
       "      <td>9.760940e+01</td>\n",
       "      <td>2.825180e+01</td>\n",
       "      <td>4.104800e+01</td>\n",
       "      <td>7.730613e+01</td>\n",
       "      <td>1.006760e+02</td>\n",
       "      <td>1.191596e+02</td>\n",
       "      <td>1.661354e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MeanRB</th>\n",
       "      <td>898.0</td>\n",
       "      <td>9.619489e+01</td>\n",
       "      <td>2.162741e+01</td>\n",
       "      <td>4.425690e+01</td>\n",
       "      <td>7.850238e+01</td>\n",
       "      <td>9.922560e+01</td>\n",
       "      <td>1.133323e+02</td>\n",
       "      <td>1.482114e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StdDevRR</th>\n",
       "      <td>898.0</td>\n",
       "      <td>2.904744e+01</td>\n",
       "      <td>6.306931e+00</td>\n",
       "      <td>7.303800e+00</td>\n",
       "      <td>2.490152e+01</td>\n",
       "      <td>2.970945e+01</td>\n",
       "      <td>3.327437e+01</td>\n",
       "      <td>4.857120e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StdDevRG</th>\n",
       "      <td>898.0</td>\n",
       "      <td>2.638336e+01</td>\n",
       "      <td>5.462164e+00</td>\n",
       "      <td>8.655700e+00</td>\n",
       "      <td>2.228965e+01</td>\n",
       "      <td>2.563830e+01</td>\n",
       "      <td>2.990533e+01</td>\n",
       "      <td>4.551070e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StdDevRB</th>\n",
       "      <td>898.0</td>\n",
       "      <td>2.614833e+01</td>\n",
       "      <td>4.905078e+00</td>\n",
       "      <td>5.148600e+00</td>\n",
       "      <td>2.289098e+01</td>\n",
       "      <td>2.646900e+01</td>\n",
       "      <td>2.948238e+01</td>\n",
       "      <td>4.242280e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkewRR</th>\n",
       "      <td>898.0</td>\n",
       "      <td>8.926615e-02</td>\n",
       "      <td>9.432854e-01</td>\n",
       "      <td>-1.724200e+00</td>\n",
       "      <td>-5.499000e-01</td>\n",
       "      <td>-1.627000e-01</td>\n",
       "      <td>4.710250e-01</td>\n",
       "      <td>3.223600e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkewRG</th>\n",
       "      <td>898.0</td>\n",
       "      <td>5.641388e-01</td>\n",
       "      <td>1.039813e+00</td>\n",
       "      <td>-1.834400e+00</td>\n",
       "      <td>-2.302000e-01</td>\n",
       "      <td>2.437500e-01</td>\n",
       "      <td>1.406550e+00</td>\n",
       "      <td>3.697100e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkewRB</th>\n",
       "      <td>898.0</td>\n",
       "      <td>2.505179e-01</td>\n",
       "      <td>6.329178e-01</td>\n",
       "      <td>-1.029100e+00</td>\n",
       "      <td>-1.969500e-01</td>\n",
       "      <td>1.355500e-01</td>\n",
       "      <td>5.939500e-01</td>\n",
       "      <td>3.092300e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KurtosisRR</th>\n",
       "      <td>898.0</td>\n",
       "      <td>4.247845e+00</td>\n",
       "      <td>2.892357e+00</td>\n",
       "      <td>1.708200e+00</td>\n",
       "      <td>2.536625e+00</td>\n",
       "      <td>3.069800e+00</td>\n",
       "      <td>4.449850e+00</td>\n",
       "      <td>2.617110e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KurtosisRG</th>\n",
       "      <td>898.0</td>\n",
       "      <td>5.110894e+00</td>\n",
       "      <td>3.745463e+00</td>\n",
       "      <td>1.607600e+00</td>\n",
       "      <td>2.508850e+00</td>\n",
       "      <td>3.127800e+00</td>\n",
       "      <td>7.320400e+00</td>\n",
       "      <td>2.673670e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KurtosisRB</th>\n",
       "      <td>898.0</td>\n",
       "      <td>3.780928e+00</td>\n",
       "      <td>2.049831e+00</td>\n",
       "      <td>1.767200e+00</td>\n",
       "      <td>2.577275e+00</td>\n",
       "      <td>3.080700e+00</td>\n",
       "      <td>4.283125e+00</td>\n",
       "      <td>3.224950e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EntropyRR</th>\n",
       "      <td>898.0</td>\n",
       "      <td>-3.185021e+10</td>\n",
       "      <td>2.037241e+10</td>\n",
       "      <td>-1.091224e+11</td>\n",
       "      <td>-4.429444e+10</td>\n",
       "      <td>-2.826156e+10</td>\n",
       "      <td>-1.460482e+10</td>\n",
       "      <td>-1.627316e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EntropyRG</th>\n",
       "      <td>898.0</td>\n",
       "      <td>-2.901860e+10</td>\n",
       "      <td>1.712952e+10</td>\n",
       "      <td>-9.261697e+10</td>\n",
       "      <td>-3.894638e+10</td>\n",
       "      <td>-2.620990e+10</td>\n",
       "      <td>-1.433105e+10</td>\n",
       "      <td>-5.627727e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EntropyRB</th>\n",
       "      <td>898.0</td>\n",
       "      <td>-2.771876e+10</td>\n",
       "      <td>1.484137e+10</td>\n",
       "      <td>-8.747177e+10</td>\n",
       "      <td>-3.564534e+10</td>\n",
       "      <td>-2.392928e+10</td>\n",
       "      <td>-1.660367e+10</td>\n",
       "      <td>-4.370435e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALLdaub4RR</th>\n",
       "      <td>898.0</td>\n",
       "      <td>5.008289e+01</td>\n",
       "      <td>1.606313e+01</td>\n",
       "      <td>1.519110e+01</td>\n",
       "      <td>3.822442e+01</td>\n",
       "      <td>5.384130e+01</td>\n",
       "      <td>6.306335e+01</td>\n",
       "      <td>7.982890e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALLdaub4RG</th>\n",
       "      <td>898.0</td>\n",
       "      <td>4.880568e+01</td>\n",
       "      <td>1.412591e+01</td>\n",
       "      <td>2.052470e+01</td>\n",
       "      <td>3.865452e+01</td>\n",
       "      <td>5.033780e+01</td>\n",
       "      <td>5.957360e+01</td>\n",
       "      <td>8.306490e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALLdaub4RB</th>\n",
       "      <td>898.0</td>\n",
       "      <td>4.809839e+01</td>\n",
       "      <td>1.081386e+01</td>\n",
       "      <td>2.213000e+01</td>\n",
       "      <td>3.925073e+01</td>\n",
       "      <td>4.961410e+01</td>\n",
       "      <td>5.666667e+01</td>\n",
       "      <td>7.410460e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count          mean           std           min           25%  \\\n",
       "AREA           898.0  2.982952e+05  1.072452e+05  1.987000e+03  2.069480e+05   \n",
       "PERIMETER      898.0  2.057661e+03  4.100125e+02  9.118280e+02  1.726091e+03   \n",
       "MAJOR_AXIS     898.0  7.508120e+02  1.440593e+02  3.367227e+02  6.410686e+02   \n",
       "MINOR_AXIS     898.0  4.958728e+02  1.142689e+02  2.283200e+00  4.046844e+02   \n",
       "ECCENTRICITY   898.0  7.374678e-01  8.872739e-02  3.448000e-01  6.856250e-01   \n",
       "EQDIASQ        898.0  6.045779e+02  1.195939e+02  5.029840e+01  5.133171e+02   \n",
       "SOLIDITY       898.0  9.818403e-01  1.815742e-02  8.366000e-01  9.788250e-01   \n",
       "CONVEX_AREA    898.0  3.038456e+05  1.088157e+05  2.257000e+03  2.100228e+05   \n",
       "EXTENT         898.0  7.362671e-01  5.374518e-02  5.123000e-01  7.058750e-01   \n",
       "ASPECT_RATIO   898.0  2.131102e+00  1.782078e+01  1.065300e+00  1.373725e+00   \n",
       "ROUNDNESS      898.0  8.577200e-01  7.083882e-02  4.800000e-03  8.277500e-01   \n",
       "COMPACTNESS    898.0  8.071903e-01  6.217535e-02  4.110000e-02  7.680500e-01   \n",
       "SHAPEFACTOR_1  898.0  3.428396e-03  2.045601e-02  1.700000e-03  2.200000e-03   \n",
       "SHAPEFACTOR_2  898.0  1.794432e-03  4.279168e-04  1.100000e-03  1.500000e-03   \n",
       "SHAPEFACTOR_3  898.0  6.554197e-01  9.431447e-02  1.700000e-03  5.899750e-01   \n",
       "SHAPEFACTOR_4  898.0  9.886796e-01  2.047314e-02  7.568000e-01  9.893000e-01   \n",
       "MeanRR         898.0  1.001659e+02  3.212655e+01  3.038260e+01  7.644800e+01   \n",
       "MeanRG         898.0  9.760940e+01  2.825180e+01  4.104800e+01  7.730613e+01   \n",
       "MeanRB         898.0  9.619489e+01  2.162741e+01  4.425690e+01  7.850238e+01   \n",
       "StdDevRR       898.0  2.904744e+01  6.306931e+00  7.303800e+00  2.490152e+01   \n",
       "StdDevRG       898.0  2.638336e+01  5.462164e+00  8.655700e+00  2.228965e+01   \n",
       "StdDevRB       898.0  2.614833e+01  4.905078e+00  5.148600e+00  2.289098e+01   \n",
       "SkewRR         898.0  8.926615e-02  9.432854e-01 -1.724200e+00 -5.499000e-01   \n",
       "SkewRG         898.0  5.641388e-01  1.039813e+00 -1.834400e+00 -2.302000e-01   \n",
       "SkewRB         898.0  2.505179e-01  6.329178e-01 -1.029100e+00 -1.969500e-01   \n",
       "KurtosisRR     898.0  4.247845e+00  2.892357e+00  1.708200e+00  2.536625e+00   \n",
       "KurtosisRG     898.0  5.110894e+00  3.745463e+00  1.607600e+00  2.508850e+00   \n",
       "KurtosisRB     898.0  3.780928e+00  2.049831e+00  1.767200e+00  2.577275e+00   \n",
       "EntropyRR      898.0 -3.185021e+10  2.037241e+10 -1.091224e+11 -4.429444e+10   \n",
       "EntropyRG      898.0 -2.901860e+10  1.712952e+10 -9.261697e+10 -3.894638e+10   \n",
       "EntropyRB      898.0 -2.771876e+10  1.484137e+10 -8.747177e+10 -3.564534e+10   \n",
       "ALLdaub4RR     898.0  5.008289e+01  1.606313e+01  1.519110e+01  3.822442e+01   \n",
       "ALLdaub4RG     898.0  4.880568e+01  1.412591e+01  2.052470e+01  3.865452e+01   \n",
       "ALLdaub4RB     898.0  4.809839e+01  1.081386e+01  2.213000e+01  3.925073e+01   \n",
       "\n",
       "                        50%           75%           max  \n",
       "AREA           3.198330e+05  3.825730e+05  5.460630e+05  \n",
       "PERIMETER      2.196345e+03  2.389717e+03  2.811997e+03  \n",
       "MAJOR_AXIS     7.913634e+02  8.586338e+02  1.222723e+03  \n",
       "MINOR_AXIS     4.950548e+02  5.890317e+02  7.664536e+02  \n",
       "ECCENTRICITY   7.547000e-01  8.021500e-01  1.000000e+00  \n",
       "EQDIASQ        6.381409e+02  6.979305e+02  8.338279e+02  \n",
       "SOLIDITY       9.873000e-01  9.918000e-01  9.974000e-01  \n",
       "CONVEX_AREA    3.272070e+05  3.888040e+05  5.525980e+05  \n",
       "EXTENT         7.469500e-01  7.758500e-01  8.562000e-01  \n",
       "ASPECT_RATIO   1.524150e+00  1.674750e+00  5.355257e+02  \n",
       "ROUNDNESS      8.677500e-01  8.995000e-01  9.773000e-01  \n",
       "COMPACTNESS    8.049500e-01  8.488750e-01  9.681000e-01  \n",
       "SHAPEFACTOR_1  2.600000e-03  3.200000e-03  6.154000e-01  \n",
       "SHAPEFACTOR_2  1.600000e-03  2.075000e-03  4.300000e-03  \n",
       "SHAPEFACTOR_3  6.479500e-01  7.206250e-01  9.373000e-01  \n",
       "SHAPEFACTOR_4  9.936000e-01  9.964000e-01  9.995000e-01  \n",
       "MeanRR         1.076825e+02  1.261275e+02  1.596494e+02  \n",
       "MeanRG         1.006760e+02  1.191596e+02  1.661354e+02  \n",
       "MeanRB         9.922560e+01  1.133323e+02  1.482114e+02  \n",
       "StdDevRR       2.970945e+01  3.327437e+01  4.857120e+01  \n",
       "StdDevRG       2.563830e+01  2.990533e+01  4.551070e+01  \n",
       "StdDevRB       2.646900e+01  2.948238e+01  4.242280e+01  \n",
       "SkewRR        -1.627000e-01  4.710250e-01  3.223600e+00  \n",
       "SkewRG         2.437500e-01  1.406550e+00  3.697100e+00  \n",
       "SkewRB         1.355500e-01  5.939500e-01  3.092300e+00  \n",
       "KurtosisRR     3.069800e+00  4.449850e+00  2.617110e+01  \n",
       "KurtosisRG     3.127800e+00  7.320400e+00  2.673670e+01  \n",
       "KurtosisRB     3.080700e+00  4.283125e+00  3.224950e+01  \n",
       "EntropyRR     -2.826156e+10 -1.460482e+10 -1.627316e+08  \n",
       "EntropyRG     -2.620990e+10 -1.433105e+10 -5.627727e+08  \n",
       "EntropyRB     -2.392928e+10 -1.660367e+10 -4.370435e+08  \n",
       "ALLdaub4RR     5.384130e+01  6.306335e+01  7.982890e+01  \n",
       "ALLdaub4RG     5.033780e+01  5.957360e+01  8.306490e+01  \n",
       "ALLdaub4RB     4.961410e+01  5.666667e+01  7.410460e+01  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AREA             0\n",
       "PERIMETER        0\n",
       "MAJOR_AXIS       0\n",
       "MINOR_AXIS       0\n",
       "ECCENTRICITY     0\n",
       "EQDIASQ          0\n",
       "SOLIDITY         0\n",
       "CONVEX_AREA      0\n",
       "EXTENT           0\n",
       "ASPECT_RATIO     0\n",
       "ROUNDNESS        0\n",
       "COMPACTNESS      0\n",
       "SHAPEFACTOR_1    0\n",
       "SHAPEFACTOR_2    0\n",
       "SHAPEFACTOR_3    0\n",
       "SHAPEFACTOR_4    0\n",
       "MeanRR           0\n",
       "MeanRG           0\n",
       "MeanRB           0\n",
       "StdDevRR         0\n",
       "StdDevRG         0\n",
       "StdDevRB         0\n",
       "SkewRR           0\n",
       "SkewRG           0\n",
       "SkewRB           0\n",
       "KurtosisRR       0\n",
       "KurtosisRG       0\n",
       "KurtosisRB       0\n",
       "EntropyRR        0\n",
       "EntropyRG        0\n",
       "EntropyRB        0\n",
       "ALLdaub4RR       0\n",
       "ALLdaub4RG       0\n",
       "ALLdaub4RB       0\n",
       "Class            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(898, 35)\n",
      "['BERHI' 'DEGLET' 'DOKOL' 'IRAQI' 'ROTANA' 'SAFAVI' 'SOGAY']\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df[\"Class\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop([\"Class\"],axis=1)\n",
    "y = df[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled = minmax_scale(x)\n",
    "x = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.772274</td>\n",
       "      <td>0.772079</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.841941</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>0.871512</td>\n",
       "      <td>0.983209</td>\n",
       "      <td>0.767108</td>\n",
       "      <td>0.787438</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395739</td>\n",
       "      <td>0.062495</td>\n",
       "      <td>0.053715</td>\n",
       "      <td>0.080752</td>\n",
       "      <td>0.458253</td>\n",
       "      <td>0.455197</td>\n",
       "      <td>0.546327</td>\n",
       "      <td>0.673513</td>\n",
       "      <td>0.550537</td>\n",
       "      <td>0.494665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.617835</td>\n",
       "      <td>0.617480</td>\n",
       "      <td>0.436904</td>\n",
       "      <td>0.775906</td>\n",
       "      <td>0.342186</td>\n",
       "      <td>0.773229</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.611906</td>\n",
       "      <td>0.776970</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350002</td>\n",
       "      <td>0.037387</td>\n",
       "      <td>0.040885</td>\n",
       "      <td>0.046033</td>\n",
       "      <td>0.687312</td>\n",
       "      <td>0.599151</td>\n",
       "      <td>0.643352</td>\n",
       "      <td>0.538923</td>\n",
       "      <td>0.516341</td>\n",
       "      <td>0.494501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.964674</td>\n",
       "      <td>0.913374</td>\n",
       "      <td>0.681733</td>\n",
       "      <td>0.933143</td>\n",
       "      <td>0.464896</td>\n",
       "      <td>0.981104</td>\n",
       "      <td>0.992537</td>\n",
       "      <td>0.956896</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472509</td>\n",
       "      <td>0.083531</td>\n",
       "      <td>0.089677</td>\n",
       "      <td>0.096843</td>\n",
       "      <td>0.139263</td>\n",
       "      <td>0.194220</td>\n",
       "      <td>0.312066</td>\n",
       "      <td>0.777967</td>\n",
       "      <td>0.619782</td>\n",
       "      <td>0.573507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.761063</td>\n",
       "      <td>0.757502</td>\n",
       "      <td>0.554467</td>\n",
       "      <td>0.841456</td>\n",
       "      <td>0.430098</td>\n",
       "      <td>0.864727</td>\n",
       "      <td>0.983831</td>\n",
       "      <td>0.755891</td>\n",
       "      <td>0.766502</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687121</td>\n",
       "      <td>0.136202</td>\n",
       "      <td>0.278800</td>\n",
       "      <td>0.213061</td>\n",
       "      <td>0.707125</td>\n",
       "      <td>0.657830</td>\n",
       "      <td>0.665214</td>\n",
       "      <td>0.436260</td>\n",
       "      <td>0.377376</td>\n",
       "      <td>0.366683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.635159</td>\n",
       "      <td>0.657060</td>\n",
       "      <td>0.482240</td>\n",
       "      <td>0.759716</td>\n",
       "      <td>0.460470</td>\n",
       "      <td>0.784821</td>\n",
       "      <td>0.958955</td>\n",
       "      <td>0.633316</td>\n",
       "      <td>0.711253</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464794</td>\n",
       "      <td>0.040608</td>\n",
       "      <td>0.054459</td>\n",
       "      <td>0.086850</td>\n",
       "      <td>0.634560</td>\n",
       "      <td>0.615256</td>\n",
       "      <td>0.710963</td>\n",
       "      <td>0.581443</td>\n",
       "      <td>0.485820</td>\n",
       "      <td>0.395128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>0.465773</td>\n",
       "      <td>0.533393</td>\n",
       "      <td>0.400815</td>\n",
       "      <td>0.621454</td>\n",
       "      <td>0.578907</td>\n",
       "      <td>0.663606</td>\n",
       "      <td>0.882463</td>\n",
       "      <td>0.470201</td>\n",
       "      <td>0.624019</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215776</td>\n",
       "      <td>0.021833</td>\n",
       "      <td>0.030355</td>\n",
       "      <td>0.031264</td>\n",
       "      <td>0.769330</td>\n",
       "      <td>0.797879</td>\n",
       "      <td>0.792768</td>\n",
       "      <td>0.524396</td>\n",
       "      <td>0.360048</td>\n",
       "      <td>0.390293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>0.668908</td>\n",
       "      <td>0.922547</td>\n",
       "      <td>0.585486</td>\n",
       "      <td>0.718768</td>\n",
       "      <td>0.640415</td>\n",
       "      <td>0.806960</td>\n",
       "      <td>0.684080</td>\n",
       "      <td>0.698311</td>\n",
       "      <td>0.457110</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385840</td>\n",
       "      <td>0.069603</td>\n",
       "      <td>0.078511</td>\n",
       "      <td>0.072954</td>\n",
       "      <td>0.711430</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>0.783525</td>\n",
       "      <td>0.489149</td>\n",
       "      <td>0.297087</td>\n",
       "      <td>0.277447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0.463801</td>\n",
       "      <td>0.534115</td>\n",
       "      <td>0.463625</td>\n",
       "      <td>0.567071</td>\n",
       "      <td>0.713980</td>\n",
       "      <td>0.662076</td>\n",
       "      <td>0.969527</td>\n",
       "      <td>0.461528</td>\n",
       "      <td>0.615586</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314359</td>\n",
       "      <td>0.023207</td>\n",
       "      <td>0.035871</td>\n",
       "      <td>0.030441</td>\n",
       "      <td>0.797356</td>\n",
       "      <td>0.793251</td>\n",
       "      <td>0.802894</td>\n",
       "      <td>0.447747</td>\n",
       "      <td>0.324174</td>\n",
       "      <td>0.362618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>0.435542</td>\n",
       "      <td>0.523343</td>\n",
       "      <td>0.428810</td>\n",
       "      <td>0.575194</td>\n",
       "      <td>0.675366</td>\n",
       "      <td>0.639781</td>\n",
       "      <td>0.769900</td>\n",
       "      <td>0.447973</td>\n",
       "      <td>0.532422</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378900</td>\n",
       "      <td>0.039599</td>\n",
       "      <td>0.042970</td>\n",
       "      <td>0.033852</td>\n",
       "      <td>0.762427</td>\n",
       "      <td>0.774730</td>\n",
       "      <td>0.777411</td>\n",
       "      <td>0.557500</td>\n",
       "      <td>0.402805</td>\n",
       "      <td>0.452067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>0.628230</td>\n",
       "      <td>0.724906</td>\n",
       "      <td>0.549798</td>\n",
       "      <td>0.696824</td>\n",
       "      <td>0.634768</td>\n",
       "      <td>0.780204</td>\n",
       "      <td>0.879975</td>\n",
       "      <td>0.634543</td>\n",
       "      <td>0.528642</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.354467</td>\n",
       "      <td>0.032932</td>\n",
       "      <td>0.056878</td>\n",
       "      <td>0.043281</td>\n",
       "      <td>0.707959</td>\n",
       "      <td>0.783609</td>\n",
       "      <td>0.761218</td>\n",
       "      <td>0.497454</td>\n",
       "      <td>0.290564</td>\n",
       "      <td>0.337546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>898 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0    0.772274  0.772079  0.565604  0.841941  0.446429  0.871512  0.983209   \n",
       "1    0.617835  0.617480  0.436904  0.775906  0.342186  0.773229  1.000000   \n",
       "2    0.964674  0.913374  0.681733  0.933143  0.464896  0.981104  0.992537   \n",
       "3    0.761063  0.757502  0.554467  0.841456  0.430098  0.864727  0.983831   \n",
       "4    0.635159  0.657060  0.482240  0.759716  0.460470  0.784821  0.958955   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "893  0.465773  0.533393  0.400815  0.621454  0.578907  0.663606  0.882463   \n",
       "894  0.668908  0.922547  0.585486  0.718768  0.640415  0.806960  0.684080   \n",
       "895  0.463801  0.534115  0.463625  0.567071  0.713980  0.662076  0.969527   \n",
       "896  0.435542  0.523343  0.428810  0.575194  0.675366  0.639781  0.769900   \n",
       "897  0.628230  0.724906  0.549798  0.696824  0.634768  0.780204  0.879975   \n",
       "\n",
       "           7         8         9   ...        24        25        26  \\\n",
       "0    0.767108  0.787438  0.000435  ...  0.395739  0.062495  0.053715   \n",
       "1    0.611906  0.776970  0.000282  ...  0.350002  0.037387  0.040885   \n",
       "2    0.956896  0.736842  0.000467  ...  0.472509  0.083531  0.089677   \n",
       "3    0.755891  0.766502  0.000408  ...  0.687121  0.136202  0.278800   \n",
       "4    0.633316  0.711253  0.000459  ...  0.464794  0.040608  0.054459   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "893  0.470201  0.624019  0.000720  ...  0.215776  0.021833  0.030355   \n",
       "894  0.698311  0.457110  0.000909  ...  0.385840  0.069603  0.078511   \n",
       "895  0.461528  0.615586  0.001217  ...  0.314359  0.023207  0.035871   \n",
       "896  0.447973  0.532422  0.001042  ...  0.378900  0.039599  0.042970   \n",
       "897  0.634543  0.528642  0.000889  ...  0.354467  0.032932  0.056878   \n",
       "\n",
       "           27        28        29        30        31        32        33  \n",
       "0    0.080752  0.458253  0.455197  0.546327  0.673513  0.550537  0.494665  \n",
       "1    0.046033  0.687312  0.599151  0.643352  0.538923  0.516341  0.494501  \n",
       "2    0.096843  0.139263  0.194220  0.312066  0.777967  0.619782  0.573507  \n",
       "3    0.213061  0.707125  0.657830  0.665214  0.436260  0.377376  0.366683  \n",
       "4    0.086850  0.634560  0.615256  0.710963  0.581443  0.485820  0.395128  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "893  0.031264  0.769330  0.797879  0.792768  0.524396  0.360048  0.390293  \n",
       "894  0.072954  0.711430  0.767717  0.783525  0.489149  0.297087  0.277447  \n",
       "895  0.030441  0.797356  0.793251  0.802894  0.447747  0.324174  0.362618  \n",
       "896  0.033852  0.762427  0.774730  0.777411  0.557500  0.402805  0.452067  \n",
       "897  0.043281  0.707959  0.783609  0.761218  0.497454  0.290564  0.337546  \n",
       "\n",
       "[898 rows x 34 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      BERHI\n",
       "1      BERHI\n",
       "2      BERHI\n",
       "3      BERHI\n",
       "4      BERHI\n",
       "       ...  \n",
       "893    SOGAY\n",
       "894    SOGAY\n",
       "895    SOGAY\n",
       "896    SOGAY\n",
       "897    SOGAY\n",
       "Name: Class, Length: 898, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = LabelEncoder().fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_temporary,y_train,y_temporary = train_test_split(x,y, train_size=0.8)\n",
    "\n",
    "x_val,x_test,y_val,y_test = train_test_split(x_temporary,y_temporary, train_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>0.617489</td>\n",
       "      <td>0.724352</td>\n",
       "      <td>0.617823</td>\n",
       "      <td>0.641595</td>\n",
       "      <td>0.741148</td>\n",
       "      <td>0.772997</td>\n",
       "      <td>0.922264</td>\n",
       "      <td>0.619354</td>\n",
       "      <td>0.683920</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408308</td>\n",
       "      <td>0.120456</td>\n",
       "      <td>0.501216</td>\n",
       "      <td>0.095190</td>\n",
       "      <td>0.952186</td>\n",
       "      <td>0.924965</td>\n",
       "      <td>0.897321</td>\n",
       "      <td>0.092803</td>\n",
       "      <td>0.069250</td>\n",
       "      <td>0.106927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>0.774960</td>\n",
       "      <td>0.835248</td>\n",
       "      <td>0.609249</td>\n",
       "      <td>0.818446</td>\n",
       "      <td>0.538919</td>\n",
       "      <td>0.873130</td>\n",
       "      <td>0.886194</td>\n",
       "      <td>0.782057</td>\n",
       "      <td>0.639430</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207721</td>\n",
       "      <td>0.033263</td>\n",
       "      <td>0.027538</td>\n",
       "      <td>0.032629</td>\n",
       "      <td>0.321033</td>\n",
       "      <td>0.327590</td>\n",
       "      <td>0.410932</td>\n",
       "      <td>0.769137</td>\n",
       "      <td>0.633313</td>\n",
       "      <td>0.639739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>0.880530</td>\n",
       "      <td>0.861666</td>\n",
       "      <td>0.575976</td>\n",
       "      <td>0.945259</td>\n",
       "      <td>0.264042</td>\n",
       "      <td>0.934655</td>\n",
       "      <td>0.960821</td>\n",
       "      <td>0.877852</td>\n",
       "      <td>0.701367</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.442932</td>\n",
       "      <td>0.069575</td>\n",
       "      <td>0.095375</td>\n",
       "      <td>0.123193</td>\n",
       "      <td>0.582917</td>\n",
       "      <td>0.518674</td>\n",
       "      <td>0.550369</td>\n",
       "      <td>0.501570</td>\n",
       "      <td>0.435787</td>\n",
       "      <td>0.441960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>0.654456</td>\n",
       "      <td>0.752506</td>\n",
       "      <td>0.633798</td>\n",
       "      <td>0.665434</td>\n",
       "      <td>0.729243</td>\n",
       "      <td>0.797549</td>\n",
       "      <td>0.879975</td>\n",
       "      <td>0.661068</td>\n",
       "      <td>0.403024</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456568</td>\n",
       "      <td>0.318699</td>\n",
       "      <td>0.285092</td>\n",
       "      <td>0.098943</td>\n",
       "      <td>0.914167</td>\n",
       "      <td>0.875750</td>\n",
       "      <td>0.831541</td>\n",
       "      <td>0.158396</td>\n",
       "      <td>0.138816</td>\n",
       "      <td>0.223936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.948926</td>\n",
       "      <td>0.654233</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.310287</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942786</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.752254</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326224</td>\n",
       "      <td>0.071774</td>\n",
       "      <td>0.084921</td>\n",
       "      <td>0.099887</td>\n",
       "      <td>0.127203</td>\n",
       "      <td>0.144427</td>\n",
       "      <td>0.205692</td>\n",
       "      <td>0.764687</td>\n",
       "      <td>0.629803</td>\n",
       "      <td>0.644948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>0.715689</td>\n",
       "      <td>0.859374</td>\n",
       "      <td>0.633234</td>\n",
       "      <td>0.726479</td>\n",
       "      <td>0.670177</td>\n",
       "      <td>0.836747</td>\n",
       "      <td>0.798507</td>\n",
       "      <td>0.732864</td>\n",
       "      <td>0.608607</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.462634</td>\n",
       "      <td>0.085775</td>\n",
       "      <td>0.444946</td>\n",
       "      <td>0.138713</td>\n",
       "      <td>0.945952</td>\n",
       "      <td>0.911536</td>\n",
       "      <td>0.884375</td>\n",
       "      <td>0.075809</td>\n",
       "      <td>0.064352</td>\n",
       "      <td>0.097969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>0.887527</td>\n",
       "      <td>0.857900</td>\n",
       "      <td>0.604987</td>\n",
       "      <td>0.932501</td>\n",
       "      <td>0.349206</td>\n",
       "      <td>0.938600</td>\n",
       "      <td>0.988806</td>\n",
       "      <td>0.880861</td>\n",
       "      <td>0.752835</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379992</td>\n",
       "      <td>0.239616</td>\n",
       "      <td>0.222602</td>\n",
       "      <td>0.108502</td>\n",
       "      <td>0.685265</td>\n",
       "      <td>0.567896</td>\n",
       "      <td>0.450001</td>\n",
       "      <td>0.427179</td>\n",
       "      <td>0.408873</td>\n",
       "      <td>0.531271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>0.683447</td>\n",
       "      <td>0.745552</td>\n",
       "      <td>0.587525</td>\n",
       "      <td>0.725901</td>\n",
       "      <td>0.634005</td>\n",
       "      <td>0.816325</td>\n",
       "      <td>0.923507</td>\n",
       "      <td>0.685448</td>\n",
       "      <td>0.612387</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.427767</td>\n",
       "      <td>0.236513</td>\n",
       "      <td>0.399923</td>\n",
       "      <td>0.078419</td>\n",
       "      <td>0.972473</td>\n",
       "      <td>0.929192</td>\n",
       "      <td>0.884947</td>\n",
       "      <td>0.001694</td>\n",
       "      <td>0.028423</td>\n",
       "      <td>0.102412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>0.647103</td>\n",
       "      <td>0.831666</td>\n",
       "      <td>0.603786</td>\n",
       "      <td>0.684250</td>\n",
       "      <td>0.691850</td>\n",
       "      <td>0.792721</td>\n",
       "      <td>0.743781</td>\n",
       "      <td>0.668700</td>\n",
       "      <td>0.515557</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300699</td>\n",
       "      <td>0.342838</td>\n",
       "      <td>0.293727</td>\n",
       "      <td>0.074007</td>\n",
       "      <td>0.888319</td>\n",
       "      <td>0.784030</td>\n",
       "      <td>0.724903</td>\n",
       "      <td>0.228366</td>\n",
       "      <td>0.299116</td>\n",
       "      <td>0.394816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>0.272778</td>\n",
       "      <td>0.300510</td>\n",
       "      <td>0.264369</td>\n",
       "      <td>0.437853</td>\n",
       "      <td>0.706044</td>\n",
       "      <td>0.494304</td>\n",
       "      <td>0.940299</td>\n",
       "      <td>0.272551</td>\n",
       "      <td>0.747601</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088683</td>\n",
       "      <td>0.054707</td>\n",
       "      <td>0.034160</td>\n",
       "      <td>0.029742</td>\n",
       "      <td>0.703655</td>\n",
       "      <td>0.656278</td>\n",
       "      <td>0.747697</td>\n",
       "      <td>0.865441</td>\n",
       "      <td>0.815223</td>\n",
       "      <td>0.734640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>718 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "782  0.617489  0.724352  0.617823  0.641595  0.741148  0.772997  0.922264   \n",
       "447  0.774960  0.835248  0.609249  0.818446  0.538919  0.873130  0.886194   \n",
       "426  0.880530  0.861666  0.575976  0.945259  0.264042  0.934655  0.960821   \n",
       "649  0.654456  0.752506  0.633798  0.665434  0.729243  0.797549  0.879975   \n",
       "8    1.000000  0.948926  0.654233  1.000000  0.310287  1.000000  0.942786   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "736  0.715689  0.859374  0.633234  0.726479  0.670177  0.836747  0.798507   \n",
       "411  0.887527  0.857900  0.604987  0.932501  0.349206  0.938600  0.988806   \n",
       "735  0.683447  0.745552  0.587525  0.725901  0.634005  0.816325  0.923507   \n",
       "751  0.647103  0.831666  0.603786  0.684250  0.691850  0.792721  0.743781   \n",
       "317  0.272778  0.300510  0.264369  0.437853  0.706044  0.494304  0.940299   \n",
       "\n",
       "           7         8         9   ...        24        25        26  \\\n",
       "782  0.619354  0.683920  0.001365  ...  0.408308  0.120456  0.501216   \n",
       "447  0.782057  0.639430  0.000620  ...  0.207721  0.033263  0.027538   \n",
       "426  0.877852  0.701367  0.000194  ...  0.442932  0.069575  0.095375   \n",
       "649  0.661068  0.403024  0.001297  ...  0.456568  0.318699  0.285092   \n",
       "8    1.000000  0.752254  0.000244  ...  0.326224  0.071774  0.084921   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "736  0.732864  0.608607  0.001020  ...  0.462634  0.085775  0.444946   \n",
       "411  0.880861  0.752835  0.000291  ...  0.379992  0.239616  0.222602   \n",
       "735  0.685448  0.612387  0.000887  ...  0.427767  0.236513  0.399923   \n",
       "751  0.668700  0.515557  0.001112  ...  0.300699  0.342838  0.293727   \n",
       "317  0.272551  0.747601  0.001178  ...  0.088683  0.054707  0.034160   \n",
       "\n",
       "           27        28        29        30        31        32        33  \n",
       "782  0.095190  0.952186  0.924965  0.897321  0.092803  0.069250  0.106927  \n",
       "447  0.032629  0.321033  0.327590  0.410932  0.769137  0.633313  0.639739  \n",
       "426  0.123193  0.582917  0.518674  0.550369  0.501570  0.435787  0.441960  \n",
       "649  0.098943  0.914167  0.875750  0.831541  0.158396  0.138816  0.223936  \n",
       "8    0.099887  0.127203  0.144427  0.205692  0.764687  0.629803  0.644948  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "736  0.138713  0.945952  0.911536  0.884375  0.075809  0.064352  0.097969  \n",
       "411  0.108502  0.685265  0.567896  0.450001  0.427179  0.408873  0.531271  \n",
       "735  0.078419  0.972473  0.929192  0.884947  0.001694  0.028423  0.102412  \n",
       "751  0.074007  0.888319  0.784030  0.724903  0.228366  0.299116  0.394816  \n",
       "317  0.029742  0.703655  0.656278  0.747697  0.865441  0.815223  0.734640  \n",
       "\n",
       "[718 rows x 34 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0.266213</td>\n",
       "      <td>0.281829</td>\n",
       "      <td>0.249868</td>\n",
       "      <td>0.436686</td>\n",
       "      <td>0.692460</td>\n",
       "      <td>0.487632</td>\n",
       "      <td>0.965796</td>\n",
       "      <td>0.264870</td>\n",
       "      <td>0.810119</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104940</td>\n",
       "      <td>0.061648</td>\n",
       "      <td>0.043615</td>\n",
       "      <td>0.027921</td>\n",
       "      <td>0.726789</td>\n",
       "      <td>0.671925</td>\n",
       "      <td>0.720709</td>\n",
       "      <td>0.835121</td>\n",
       "      <td>0.808568</td>\n",
       "      <td>0.804193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.288447</td>\n",
       "      <td>0.308166</td>\n",
       "      <td>0.239919</td>\n",
       "      <td>0.482418</td>\n",
       "      <td>0.599359</td>\n",
       "      <td>0.509915</td>\n",
       "      <td>0.945274</td>\n",
       "      <td>0.288000</td>\n",
       "      <td>0.870020</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.311569</td>\n",
       "      <td>0.030581</td>\n",
       "      <td>0.056353</td>\n",
       "      <td>0.035857</td>\n",
       "      <td>0.861102</td>\n",
       "      <td>0.873763</td>\n",
       "      <td>0.838241</td>\n",
       "      <td>0.505639</td>\n",
       "      <td>0.361908</td>\n",
       "      <td>0.479942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.410029</td>\n",
       "      <td>0.474664</td>\n",
       "      <td>0.404661</td>\n",
       "      <td>0.538584</td>\n",
       "      <td>0.700092</td>\n",
       "      <td>0.619028</td>\n",
       "      <td>0.967040</td>\n",
       "      <td>0.408111</td>\n",
       "      <td>0.396045</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221575</td>\n",
       "      <td>0.016960</td>\n",
       "      <td>0.019364</td>\n",
       "      <td>0.019697</td>\n",
       "      <td>0.602440</td>\n",
       "      <td>0.553965</td>\n",
       "      <td>0.597506</td>\n",
       "      <td>0.795398</td>\n",
       "      <td>0.720609</td>\n",
       "      <td>0.758411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0.714123</td>\n",
       "      <td>0.846500</td>\n",
       "      <td>0.613291</td>\n",
       "      <td>0.743376</td>\n",
       "      <td>0.636142</td>\n",
       "      <td>0.835766</td>\n",
       "      <td>0.805348</td>\n",
       "      <td>0.730404</td>\n",
       "      <td>0.578657</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382467</td>\n",
       "      <td>0.206877</td>\n",
       "      <td>0.343844</td>\n",
       "      <td>0.097279</td>\n",
       "      <td>0.930873</td>\n",
       "      <td>0.882823</td>\n",
       "      <td>0.829084</td>\n",
       "      <td>0.112646</td>\n",
       "      <td>0.110838</td>\n",
       "      <td>0.195540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>0.804766</td>\n",
       "      <td>0.872891</td>\n",
       "      <td>0.685285</td>\n",
       "      <td>0.781904</td>\n",
       "      <td>0.652167</td>\n",
       "      <td>0.890903</td>\n",
       "      <td>0.946517</td>\n",
       "      <td>0.804207</td>\n",
       "      <td>0.747892</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089072</td>\n",
       "      <td>0.042182</td>\n",
       "      <td>0.055517</td>\n",
       "      <td>0.060337</td>\n",
       "      <td>0.317511</td>\n",
       "      <td>0.364962</td>\n",
       "      <td>0.234597</td>\n",
       "      <td>0.748512</td>\n",
       "      <td>0.587240</td>\n",
       "      <td>0.751604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.271688</td>\n",
       "      <td>0.275561</td>\n",
       "      <td>0.214697</td>\n",
       "      <td>0.470912</td>\n",
       "      <td>0.582418</td>\n",
       "      <td>0.493202</td>\n",
       "      <td>0.978856</td>\n",
       "      <td>0.269749</td>\n",
       "      <td>0.690317</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.335784</td>\n",
       "      <td>0.041880</td>\n",
       "      <td>0.074989</td>\n",
       "      <td>0.045594</td>\n",
       "      <td>0.897686</td>\n",
       "      <td>0.893677</td>\n",
       "      <td>0.878587</td>\n",
       "      <td>0.433678</td>\n",
       "      <td>0.344850</td>\n",
       "      <td>0.406475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>0.265424</td>\n",
       "      <td>0.280694</td>\n",
       "      <td>0.232679</td>\n",
       "      <td>0.447513</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.486825</td>\n",
       "      <td>0.947761</td>\n",
       "      <td>0.264863</td>\n",
       "      <td>0.768828</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263891</td>\n",
       "      <td>0.029763</td>\n",
       "      <td>0.047622</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>0.834705</td>\n",
       "      <td>0.841348</td>\n",
       "      <td>0.824894</td>\n",
       "      <td>0.610027</td>\n",
       "      <td>0.477662</td>\n",
       "      <td>0.560972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>0.617228</td>\n",
       "      <td>0.692182</td>\n",
       "      <td>0.539786</td>\n",
       "      <td>0.706613</td>\n",
       "      <td>0.613095</td>\n",
       "      <td>0.772821</td>\n",
       "      <td>0.818408</td>\n",
       "      <td>0.629846</td>\n",
       "      <td>0.633033</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217232</td>\n",
       "      <td>0.033655</td>\n",
       "      <td>0.039520</td>\n",
       "      <td>0.036362</td>\n",
       "      <td>0.574439</td>\n",
       "      <td>0.556963</td>\n",
       "      <td>0.610204</td>\n",
       "      <td>0.654731</td>\n",
       "      <td>0.543865</td>\n",
       "      <td>0.539667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.359319</td>\n",
       "      <td>0.419711</td>\n",
       "      <td>0.352063</td>\n",
       "      <td>0.508734</td>\n",
       "      <td>0.691392</td>\n",
       "      <td>0.575784</td>\n",
       "      <td>0.947761</td>\n",
       "      <td>0.358714</td>\n",
       "      <td>0.780459</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136628</td>\n",
       "      <td>0.068467</td>\n",
       "      <td>0.046325</td>\n",
       "      <td>0.055642</td>\n",
       "      <td>0.652089</td>\n",
       "      <td>0.667637</td>\n",
       "      <td>0.665598</td>\n",
       "      <td>0.811599</td>\n",
       "      <td>0.664038</td>\n",
       "      <td>0.746278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.548719</td>\n",
       "      <td>0.617400</td>\n",
       "      <td>0.503616</td>\n",
       "      <td>0.640907</td>\n",
       "      <td>0.660867</td>\n",
       "      <td>0.725293</td>\n",
       "      <td>0.911692</td>\n",
       "      <td>0.551338</td>\n",
       "      <td>0.750218</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261974</td>\n",
       "      <td>0.080048</td>\n",
       "      <td>0.058092</td>\n",
       "      <td>0.057883</td>\n",
       "      <td>0.535313</td>\n",
       "      <td>0.623114</td>\n",
       "      <td>0.663485</td>\n",
       "      <td>0.754057</td>\n",
       "      <td>0.540347</td>\n",
       "      <td>0.542627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "219  0.266213  0.281829  0.249868  0.436686  0.692460  0.487632  0.965796   \n",
       "220  0.288447  0.308166  0.239919  0.482418  0.599359  0.509915  0.945274   \n",
       "78   0.410029  0.474664  0.404661  0.538584  0.700092  0.619028  0.967040   \n",
       "636  0.714123  0.846500  0.613291  0.743376  0.636142  0.835766  0.805348   \n",
       "462  0.804766  0.872891  0.685285  0.781904  0.652167  0.890903  0.946517   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "239  0.271688  0.275561  0.214697  0.470912  0.582418  0.493202  0.978856   \n",
       "364  0.265424  0.280694  0.232679  0.447513  0.653846  0.486825  0.947761   \n",
       "562  0.617228  0.692182  0.539786  0.706613  0.613095  0.772821  0.818408   \n",
       "117  0.359319  0.419711  0.352063  0.508734  0.691392  0.575784  0.947761   \n",
       "114  0.548719  0.617400  0.503616  0.640907  0.660867  0.725293  0.911692   \n",
       "\n",
       "           7         8         9   ...        24        25        26  \\\n",
       "219  0.264870  0.810119  0.001115  ...  0.104940  0.061648  0.043615   \n",
       "220  0.288000  0.870020  0.000777  ...  0.311569  0.030581  0.056353   \n",
       "78   0.408111  0.396045  0.001150  ...  0.221575  0.016960  0.019364   \n",
       "636  0.730404  0.578657  0.000894  ...  0.382467  0.206877  0.343844   \n",
       "462  0.804207  0.747892  0.000951  ...  0.089072  0.042182  0.055517   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "239  0.269749  0.690317  0.000729  ...  0.335784  0.041880  0.074989   \n",
       "364  0.264863  0.768828  0.000957  ...  0.263891  0.029763  0.047622   \n",
       "562  0.629846  0.633033  0.000819  ...  0.217232  0.033655  0.039520   \n",
       "117  0.358714  0.780459  0.001110  ...  0.136628  0.068467  0.046325   \n",
       "114  0.551338  0.750218  0.000984  ...  0.261974  0.080048  0.058092   \n",
       "\n",
       "           27        28        29        30        31        32        33  \n",
       "219  0.027921  0.726789  0.671925  0.720709  0.835121  0.808568  0.804193  \n",
       "220  0.035857  0.861102  0.873763  0.838241  0.505639  0.361908  0.479942  \n",
       "78   0.019697  0.602440  0.553965  0.597506  0.795398  0.720609  0.758411  \n",
       "636  0.097279  0.930873  0.882823  0.829084  0.112646  0.110838  0.195540  \n",
       "462  0.060337  0.317511  0.364962  0.234597  0.748512  0.587240  0.751604  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "239  0.045594  0.897686  0.893677  0.878587  0.433678  0.344850  0.406475  \n",
       "364  0.032832  0.834705  0.841348  0.824894  0.610027  0.477662  0.560972  \n",
       "562  0.036362  0.574439  0.556963  0.610204  0.654731  0.543865  0.539667  \n",
       "117  0.055642  0.652089  0.667637  0.665598  0.811599  0.664038  0.746278  \n",
       "114  0.057883  0.535313  0.623114  0.663485  0.754057  0.540347  0.542627  \n",
       "\n",
       "[144 rows x 34 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 4, 3, 5, 0, 0, 5, 2, 3, 6, 2, 5, 1, 4, 2, 6, 5, 5, 1, 1, 4, 5,\n",
       "       4, 6, 4, 4, 2, 2, 2, 4, 1, 0, 4, 5, 2, 2, 4, 4, 5, 0, 2, 0, 2, 1,\n",
       "       2, 4, 1, 5, 5, 2, 0, 2, 2, 2, 1, 0, 5, 2, 5, 5, 2, 2, 1, 4, 5, 0,\n",
       "       2, 4, 0, 5, 2, 5, 2, 5, 5, 6, 2, 2, 0, 1, 5, 3, 3, 0, 1, 2, 2, 4,\n",
       "       2, 5, 2, 5, 4, 1, 2, 1, 0, 2, 5, 0, 1, 5, 4, 6, 6, 5, 4, 5, 3, 5,\n",
       "       4, 0, 2, 2, 4, 0, 5, 3, 6, 6, 5, 1, 6, 4, 2, 4, 2, 1, 2, 2, 2, 4,\n",
       "       4, 5, 4, 2, 6, 3, 4, 3, 1, 3, 2, 5, 0, 5, 6, 6, 3, 2, 6, 2, 2, 4,\n",
       "       1, 6, 5, 2, 1, 1, 1, 2, 2, 5, 4, 6, 5, 2, 3, 3, 5, 4, 5, 2, 2, 6,\n",
       "       0, 0, 2, 2, 2, 1, 5, 5, 2, 1, 4, 2, 4, 4, 5, 5, 5, 6, 6, 1, 4, 2,\n",
       "       5, 1, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 4, 4, 5, 4, 5, 1, 0, 4, 3, 5,\n",
       "       2, 2, 3, 2, 2, 6, 5, 5, 5, 4, 6, 5, 5, 5, 3, 3, 1, 3, 6, 3, 2, 5,\n",
       "       4, 2, 5, 1, 4, 3, 2, 1, 3, 2, 5, 0, 0, 5, 5, 1, 2, 5, 2, 5, 5, 1,\n",
       "       1, 2, 5, 4, 2, 6, 4, 5, 5, 0, 3, 1, 5, 3, 2, 2, 2, 2, 2, 1, 6, 5,\n",
       "       2, 5, 4, 6, 2, 6, 5, 0, 0, 0, 2, 6, 4, 1, 1, 5, 6, 3, 3, 5, 4, 5,\n",
       "       2, 2, 6, 5, 2, 4, 5, 0, 5, 3, 0, 5, 0, 4, 4, 4, 5, 1, 3, 6, 0, 5,\n",
       "       0, 2, 4, 3, 1, 4, 2, 0, 6, 2, 1, 3, 5, 4, 6, 4, 2, 6, 2, 2, 2, 5,\n",
       "       5, 6, 3, 5, 2, 6, 2, 5, 5, 6, 2, 5, 6, 2, 4, 0, 0, 4, 5, 2, 5, 5,\n",
       "       2, 5, 5, 4, 5, 4, 4, 5, 5, 0, 4, 5, 1, 6, 6, 0, 3, 3, 2, 3, 4, 1,\n",
       "       3, 1, 5, 5, 2, 6, 6, 4, 2, 2, 3, 2, 5, 2, 4, 3, 0, 5, 2, 1, 5, 4,\n",
       "       2, 5, 5, 2, 4, 4, 4, 5, 1, 6, 4, 5, 5, 4, 1, 5, 4, 1, 2, 6, 5, 3,\n",
       "       2, 4, 1, 1, 6, 5, 5, 6, 5, 4, 4, 6, 5, 2, 4, 2, 1, 4, 5, 4, 3, 2,\n",
       "       2, 5, 4, 6, 2, 5, 4, 2, 0, 5, 4, 5, 5, 4, 4, 2, 0, 2, 3, 2, 6, 0,\n",
       "       5, 2, 1, 4, 4, 5, 5, 4, 4, 6, 2, 4, 5, 1, 5, 5, 1, 5, 1, 3, 1, 5,\n",
       "       2, 2, 3, 4, 4, 3, 2, 6, 1, 3, 1, 1, 4, 3, 6, 1, 4, 2, 5, 0, 2, 0,\n",
       "       6, 6, 5, 4, 1, 2, 4, 4, 0, 4, 5, 2, 1, 4, 5, 2, 5, 5, 6, 6, 2, 4,\n",
       "       5, 2, 1, 4, 4, 4, 2, 5, 2, 5, 6, 5, 3, 2, 6, 2, 0, 2, 4, 2, 5, 2,\n",
       "       1, 3, 4, 1, 5, 2, 6, 5, 4, 6, 2, 1, 2, 3, 5, 0, 4, 5, 6, 4, 1, 6,\n",
       "       4, 0, 4, 4, 5, 2, 1, 4, 2, 3, 5, 4, 2, 5, 5, 5, 4, 3, 5, 5, 2, 2,\n",
       "       6, 4, 6, 0, 3, 2, 6, 5, 4, 5, 4, 1, 5, 3, 6, 4, 2, 2, 4, 5, 2, 3,\n",
       "       0, 6, 1, 2, 0, 5, 2, 5, 2, 1, 1, 4, 5, 1, 0, 3, 4, 2, 5, 5, 2, 4,\n",
       "       4, 6, 1, 1, 5, 4, 5, 1, 5, 4, 2, 1, 3, 0, 5, 6, 2, 4, 4, 1, 3, 1,\n",
       "       0, 6, 5, 4, 4, 2, 6, 1, 2, 4, 4, 0, 2, 5, 2, 1, 5, 4, 6, 3, 6, 1,\n",
       "       4, 2, 4, 5, 2, 0, 2, 2, 2, 5, 3, 5, 5, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 5, 4, 3, 2, 5, 2, 2, 4, 2, 6, 5, 5, 3, 2, 6, 5, 3, 2, 0,\n",
       "       1, 5, 6, 5, 2, 5, 4, 2, 2, 2, 4, 3, 5, 3, 1, 6, 3, 6, 2, 2, 6, 4,\n",
       "       4, 3, 0, 6, 6, 4, 5, 2, 2, 5, 0, 4, 6, 6, 3, 4, 5, 4, 1, 6, 2, 4,\n",
       "       4, 1, 2, 5, 2, 0, 0, 4, 3, 6, 6, 2, 2, 4, 2, 4, 2, 6, 5, 1, 2, 2,\n",
       "       2, 2, 6, 5, 2, 2, 4, 2, 0, 2, 4, 5, 5, 4, 1, 6, 6, 2, 0, 5, 5, 2,\n",
       "       3, 4, 6, 1, 2, 1, 2, 2, 3, 3, 0, 5, 5, 1, 4, 2, 4, 1, 2, 2, 0, 6,\n",
       "       0, 2, 4, 3, 1, 4, 4, 2, 2, 4, 1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of the dataset:898\n",
      "Lenght of the dataset:718\n",
      "Lenght of the dataset:36\n",
      "Lenght of the dataset:144\n"
     ]
    }
   ],
   "source": [
    "print(f\"Lenght of the dataset:{len(x)}\")\n",
    "print(f\"Lenght of the dataset:{len(x_train)}\")\n",
    "print(f\"Lenght of the dataset:{len(x_val)}\")\n",
    "print(f\"Lenght of the dataset:{len(x_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tf.keras.layers.Dense(4096,input_shape=(34,),activation=\"relu\") # input shap sütun sayısı 4096 düğüm sayısı relu de aktivasyon fonksiyonu\n",
    "model.add(input_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(4096,activation=\"relu\")) # gizli katman\n",
    "model.add(tf.keras.layers.Dropout(0.5)) # Dropout, en basit tabirle sinir ağlarında fazla uyumu önlemek için kullanılır. Belirli bir katmandaki bazı düğümlerin değerleri sıfıra ayarlanır. Bu düğümler rastgele seçilir ve “kapatılacak” düğümlerin sayısı, bırakma oranına göre seçilir. Her yinelemede, farklı düğümler seçilebilir. Bizim durumumuzda, bırakma oranını 0,5 olarak ayarladığımız için düğümlerin yarısı kapanacaktır. \n",
    "model.add(tf.keras.layers.Dense(4096,activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(4096,activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(7,activation=\"softmax\")) # çıktı katmanı 7--> hedef sınıf sayısı İkiden fazla sınıfımız olduğu için çıktı katmanında softmax aktivasyon fonksiyonunu kullanacağız. Softmax işlevi, sayıları olasılıklara dönüştürür."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])# Adam optimizer, derin öğrenme modelleri için stokastik gradyan inişinin ve \"git\" algoritmasının genişletilmiş bir sürümüdür.Bunun nedeni, Adam optimizer'ın sonuçlarının genellikle diğer tüm optimizasyon algoritmalarından daha iyi olması, daha hızlı hesaplama süresine sahip olması ve ayarlama için daha az parametre gerektirmesidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 6s 246ms/step - loss: 1.4135 - accuracy: 0.5097 - val_loss: 0.6061 - val_accuracy: 0.7500\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 6s 244ms/step - loss: 0.8365 - accuracy: 0.6852 - val_loss: 0.7673 - val_accuracy: 0.7222\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 6s 248ms/step - loss: 0.6448 - accuracy: 0.7382 - val_loss: 0.4775 - val_accuracy: 0.8056\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 6s 250ms/step - loss: 0.5525 - accuracy: 0.7869 - val_loss: 0.9441 - val_accuracy: 0.6944\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 6s 247ms/step - loss: 0.4915 - accuracy: 0.7953 - val_loss: 0.6329 - val_accuracy: 0.8333\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 6s 242ms/step - loss: 0.5653 - accuracy: 0.7855 - val_loss: 0.5508 - val_accuracy: 0.7778\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 6s 241ms/step - loss: 0.4909 - accuracy: 0.8092 - val_loss: 0.6980 - val_accuracy: 0.6944\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 6s 244ms/step - loss: 0.4649 - accuracy: 0.8148 - val_loss: 0.7127 - val_accuracy: 0.7778\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 6s 242ms/step - loss: 0.4130 - accuracy: 0.8384 - val_loss: 0.2710 - val_accuracy: 0.9167\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 6s 246ms/step - loss: 0.4711 - accuracy: 0.8106 - val_loss: 0.4486 - val_accuracy: 0.8611\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 6s 251ms/step - loss: 0.4164 - accuracy: 0.8343 - val_loss: 0.3559 - val_accuracy: 0.8056\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 6s 282ms/step - loss: 0.4510 - accuracy: 0.8134 - val_loss: 0.4239 - val_accuracy: 0.8611\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 6s 250ms/step - loss: 0.4131 - accuracy: 0.8468 - val_loss: 0.6636 - val_accuracy: 0.8056\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 6s 240ms/step - loss: 0.3298 - accuracy: 0.8691 - val_loss: 0.2895 - val_accuracy: 0.9167\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 6s 246ms/step - loss: 0.3133 - accuracy: 0.8788 - val_loss: 0.2144 - val_accuracy: 0.9444\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 6s 248ms/step - loss: 0.3553 - accuracy: 0.8635 - val_loss: 0.2625 - val_accuracy: 0.9444\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 5s 238ms/step - loss: 0.3355 - accuracy: 0.8760 - val_loss: 0.3236 - val_accuracy: 0.8889\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 6s 255ms/step - loss: 0.4024 - accuracy: 0.8565 - val_loss: 0.3327 - val_accuracy: 0.8611\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 6s 262ms/step - loss: 0.3397 - accuracy: 0.8760 - val_loss: 0.2952 - val_accuracy: 0.9722\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 6s 256ms/step - loss: 0.3440 - accuracy: 0.8788 - val_loss: 0.2663 - val_accuracy: 0.9444\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 6s 250ms/step - loss: 0.3423 - accuracy: 0.8816 - val_loss: 0.5709 - val_accuracy: 0.8611\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 6s 245ms/step - loss: 0.3579 - accuracy: 0.8802 - val_loss: 0.4088 - val_accuracy: 0.8056\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 6s 252ms/step - loss: 0.3393 - accuracy: 0.8816 - val_loss: 0.3105 - val_accuracy: 0.8333\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 6s 261ms/step - loss: 0.2666 - accuracy: 0.8997 - val_loss: 0.3906 - val_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 6s 258ms/step - loss: 0.3452 - accuracy: 0.8788 - val_loss: 0.2366 - val_accuracy: 0.9444\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 5s 238ms/step - loss: 0.3082 - accuracy: 0.8691 - val_loss: 0.1766 - val_accuracy: 0.9444\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 5s 238ms/step - loss: 0.3401 - accuracy: 0.8733 - val_loss: 0.2023 - val_accuracy: 0.9167\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 5s 236ms/step - loss: 0.3161 - accuracy: 0.8858 - val_loss: 0.3704 - val_accuracy: 0.9167\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 5s 238ms/step - loss: 0.2858 - accuracy: 0.8955 - val_loss: 0.2471 - val_accuracy: 0.9444\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 6s 240ms/step - loss: 0.2441 - accuracy: 0.9109 - val_loss: 0.2062 - val_accuracy: 0.9444\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 5s 238ms/step - loss: 0.3359 - accuracy: 0.8802 - val_loss: 0.6123 - val_accuracy: 0.8056\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 5s 237ms/step - loss: 0.3412 - accuracy: 0.8635 - val_loss: 0.3432 - val_accuracy: 0.8889\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 5s 237ms/step - loss: 0.2642 - accuracy: 0.8914 - val_loss: 0.3287 - val_accuracy: 0.8333\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 5s 235ms/step - loss: 0.2838 - accuracy: 0.8969 - val_loss: 0.3512 - val_accuracy: 0.8611\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 6s 241ms/step - loss: 0.2877 - accuracy: 0.8844 - val_loss: 0.2030 - val_accuracy: 0.9167\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 5s 235ms/step - loss: 0.3185 - accuracy: 0.8802 - val_loss: 0.2999 - val_accuracy: 0.8889\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 5s 237ms/step - loss: 0.3554 - accuracy: 0.8677 - val_loss: 0.1895 - val_accuracy: 0.9722\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 5s 236ms/step - loss: 0.2555 - accuracy: 0.9136 - val_loss: 0.1945 - val_accuracy: 0.9444\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 5s 237ms/step - loss: 0.2554 - accuracy: 0.8983 - val_loss: 0.3191 - val_accuracy: 0.8889\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 5s 235ms/step - loss: 0.2612 - accuracy: 0.9025 - val_loss: 0.1441 - val_accuracy: 0.9444\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 6s 241ms/step - loss: 0.3336 - accuracy: 0.8788 - val_loss: 0.3527 - val_accuracy: 0.8889\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 5s 238ms/step - loss: 0.2745 - accuracy: 0.8969 - val_loss: 0.1811 - val_accuracy: 0.9444\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 6s 241ms/step - loss: 0.2065 - accuracy: 0.9192 - val_loss: 0.2031 - val_accuracy: 0.8889\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 6s 243ms/step - loss: 0.3022 - accuracy: 0.8858 - val_loss: 0.4812 - val_accuracy: 0.8889\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 5s 239ms/step - loss: 0.2914 - accuracy: 0.9039 - val_loss: 0.4717 - val_accuracy: 0.8611\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 6s 245ms/step - loss: 0.2442 - accuracy: 0.9164 - val_loss: 0.1040 - val_accuracy: 0.9722\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 6s 261ms/step - loss: 0.2272 - accuracy: 0.9192 - val_loss: 0.3054 - val_accuracy: 0.8889\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 6s 254ms/step - loss: 0.2074 - accuracy: 0.9178 - val_loss: 0.1939 - val_accuracy: 0.9167\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 6s 244ms/step - loss: 0.2930 - accuracy: 0.8900 - val_loss: 0.2781 - val_accuracy: 0.8611\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 6s 241ms/step - loss: 0.3535 - accuracy: 0.8802 - val_loss: 0.1995 - val_accuracy: 0.9167\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 5s 238ms/step - loss: 0.2546 - accuracy: 0.9025 - val_loss: 0.1992 - val_accuracy: 0.9444\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 5s 238ms/step - loss: 0.2010 - accuracy: 0.9220 - val_loss: 0.2091 - val_accuracy: 0.8889\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 6s 243ms/step - loss: 0.2403 - accuracy: 0.9081 - val_loss: 0.1635 - val_accuracy: 0.9722\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 6s 261ms/step - loss: 0.2599 - accuracy: 0.8969 - val_loss: 0.5667 - val_accuracy: 0.7778\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 6s 246ms/step - loss: 0.2317 - accuracy: 0.9136 - val_loss: 0.2222 - val_accuracy: 0.9167\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 6s 257ms/step - loss: 0.2252 - accuracy: 0.9053 - val_loss: 0.2039 - val_accuracy: 0.9444\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 6s 255ms/step - loss: 0.2284 - accuracy: 0.9039 - val_loss: 0.2830 - val_accuracy: 0.8611\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 6s 247ms/step - loss: 0.2548 - accuracy: 0.9011 - val_loss: 0.2285 - val_accuracy: 0.9167\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 6s 246ms/step - loss: 0.2542 - accuracy: 0.8942 - val_loss: 0.1369 - val_accuracy: 0.9444\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 6s 251ms/step - loss: 0.1975 - accuracy: 0.9290 - val_loss: 0.3214 - val_accuracy: 0.8889\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 6s 242ms/step - loss: 0.1907 - accuracy: 0.9359 - val_loss: 0.2439 - val_accuracy: 0.8611\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 6s 245ms/step - loss: 0.2210 - accuracy: 0.9220 - val_loss: 0.1256 - val_accuracy: 0.9444\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 6s 256ms/step - loss: 0.2244 - accuracy: 0.9248 - val_loss: 0.5540 - val_accuracy: 0.8889\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 6s 252ms/step - loss: 0.3008 - accuracy: 0.9053 - val_loss: 0.3116 - val_accuracy: 0.9167\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 6s 250ms/step - loss: 0.2078 - accuracy: 0.9318 - val_loss: 0.4515 - val_accuracy: 0.9167\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 6s 252ms/step - loss: 0.2293 - accuracy: 0.9081 - val_loss: 0.3157 - val_accuracy: 0.8611\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 6s 269ms/step - loss: 0.2919 - accuracy: 0.8747 - val_loss: 0.2484 - val_accuracy: 0.9167\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 6s 263ms/step - loss: 0.2354 - accuracy: 0.9178 - val_loss: 0.2074 - val_accuracy: 0.8889\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 6s 254ms/step - loss: 0.1984 - accuracy: 0.9206 - val_loss: 0.2298 - val_accuracy: 0.9444\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 6s 257ms/step - loss: 0.2629 - accuracy: 0.8872 - val_loss: 0.1793 - val_accuracy: 0.9444\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 6s 254ms/step - loss: 0.3026 - accuracy: 0.8914 - val_loss: 0.6266 - val_accuracy: 0.8333\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 6s 251ms/step - loss: 0.2420 - accuracy: 0.9123 - val_loss: 0.1697 - val_accuracy: 0.9722\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 6s 251ms/step - loss: 0.1858 - accuracy: 0.9248 - val_loss: 0.4091 - val_accuracy: 0.8056\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 6s 246ms/step - loss: 0.2380 - accuracy: 0.9206 - val_loss: 0.1945 - val_accuracy: 0.9167\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 6s 246ms/step - loss: 0.1842 - accuracy: 0.9345 - val_loss: 0.3854 - val_accuracy: 0.8889\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 6s 252ms/step - loss: 0.1780 - accuracy: 0.9192 - val_loss: 0.1474 - val_accuracy: 0.9167\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 6s 260ms/step - loss: 0.2279 - accuracy: 0.9109 - val_loss: 0.5781 - val_accuracy: 0.8611\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 6s 251ms/step - loss: 0.2189 - accuracy: 0.9304 - val_loss: 0.2797 - val_accuracy: 0.8889\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 6s 253ms/step - loss: 0.2030 - accuracy: 0.9220 - val_loss: 0.0810 - val_accuracy: 0.9722\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 6s 250ms/step - loss: 0.1667 - accuracy: 0.9387 - val_loss: 0.1792 - val_accuracy: 0.9444\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 6s 251ms/step - loss: 0.2091 - accuracy: 0.9178 - val_loss: 0.2306 - val_accuracy: 0.8889\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 6s 253ms/step - loss: 0.2362 - accuracy: 0.9081 - val_loss: 0.1868 - val_accuracy: 0.9167\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 6s 251ms/step - loss: 0.1997 - accuracy: 0.9262 - val_loss: 0.2835 - val_accuracy: 0.8889\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 6s 242ms/step - loss: 0.2134 - accuracy: 0.9262 - val_loss: 0.2650 - val_accuracy: 0.8889\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 6s 246ms/step - loss: 0.2239 - accuracy: 0.9109 - val_loss: 0.1742 - val_accuracy: 0.9444\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 6s 246ms/step - loss: 0.2482 - accuracy: 0.9095 - val_loss: 0.1792 - val_accuracy: 0.9167\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 6s 248ms/step - loss: 0.1860 - accuracy: 0.9178 - val_loss: 0.1611 - val_accuracy: 0.9444\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 6s 254ms/step - loss: 0.2015 - accuracy: 0.9234 - val_loss: 0.2211 - val_accuracy: 0.9444\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 6s 253ms/step - loss: 0.1768 - accuracy: 0.9248 - val_loss: 0.2683 - val_accuracy: 0.9167\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 6s 252ms/step - loss: 0.2141 - accuracy: 0.9234 - val_loss: 0.1575 - val_accuracy: 0.9444\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 6s 257ms/step - loss: 0.1640 - accuracy: 0.9359 - val_loss: 0.2527 - val_accuracy: 0.9167\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 6s 246ms/step - loss: 0.2478 - accuracy: 0.9039 - val_loss: 0.2302 - val_accuracy: 0.9444\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 6s 249ms/step - loss: 0.2300 - accuracy: 0.9178 - val_loss: 0.3083 - val_accuracy: 0.9444\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 6s 248ms/step - loss: 0.2010 - accuracy: 0.9234 - val_loss: 0.1987 - val_accuracy: 0.9444\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 6s 251ms/step - loss: 0.1772 - accuracy: 0.9359 - val_loss: 0.1911 - val_accuracy: 0.9444\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 6s 249ms/step - loss: 0.2136 - accuracy: 0.9234 - val_loss: 0.4458 - val_accuracy: 0.8889\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 6s 247ms/step - loss: 0.1827 - accuracy: 0.9443 - val_loss: 0.1542 - val_accuracy: 0.9444\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 6s 250ms/step - loss: 0.1647 - accuracy: 0.9304 - val_loss: 0.2032 - val_accuracy: 0.9167\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 6s 247ms/step - loss: 0.2562 - accuracy: 0.8997 - val_loss: 0.1876 - val_accuracy: 0.9167\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 6s 250ms/step - loss: 0.2432 - accuracy: 0.9095 - val_loss: 0.1435 - val_accuracy: 0.9444\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(x_train,y_train,epochs=100,validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results.history[\"loss\"],label=\"Train\")\n",
    "plt.plot(results.history[\"val_loss\"],label=\"Test\")\n",
    "\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18458858132362366, 0.9097222089767456]\n"
     ]
    }
   ],
   "source": [
    "test_result = model.test_on_batch(x_test,y_test)\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8156a36ef2b5e5cc1ebda271ff76bc51e3d60fa787ad119300a3a2fb77f01d4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
